
## 介绍

作业调度是一个众所周知的系统设计面试问题。下面是一些可能需要设计作业调度程序的领域。

- 设计一个付款处理系统。(即每月/每周/每日支付等）。
- 设计代码部署系统。(即代码管道）

本文章的目的是设计一个简单但可扩展的作业调度系统。

## 问题声明

设计一个作业调度程序，按预定时间间隔运行作业

## 需求

功能需求

- 用户可以安排或查看作业。
- 用户可以列出所有已提交作业的当前状态。
- 作业可运行一次或循环运行。作业应在定义的计划时间后 X 个阈值时间内执行。(假设 x = 15 分钟）
- 单个作业的执行时间不超过 X 分钟（假设 x = 5 分钟）
- 工作还可以有优先级。优先级高的工作应比优先级低的工作先执行
- 作业输出应存储在文件系统中

非功能需求

- 高可用性 - 系统应始终可供用户添加/查看作业
- 高可扩展性 - 系统应可扩展至数百万个作业
- 可靠性 - 系统必须至少执行一次作业，同一作业不能由不同进程同时运行。
- 持久性--系统在任何故障情况下都不应丢失作业信息
- 延迟性 - 一旦作业被接受，系统应立即反馈用户。用户无需等待作业完成。

## 流量和存储量估算（保守计算）

- 每天提交的工作总量 = 100 M (million)（或 1000 QPS）

我们可以看到，单个作业最多只能运行 5 分钟。因此，系统是 CPU 密集的，受限CPU的能力。

### CPU

现代 CPU 可以有 16 个核心，每个核心可以使用 2 个线程。每个任务最多可运行 5 分钟。

> # jobs can be executed by one machine = (16 cores*2 threads)/ (5 minutes*60) = **0.10 jobs per second** (or ~8000 jobs per day)

> # of machines needed to run 1000 QPS = 1000/0.10 = **10000** (wow 😮 !)

需要10000台CPU 16核心的机器才可以满足需求。

### 内存

假设每项工作可以使用 5 MB 内存。您可以根据与面试官的讨论情况和用例对这一数字进行微调

> A modern machine with 16 GB ram can hold up-to = (16 GB/5 MB * 5 minutes * 60) =**10 jobs per second**

> # of machines needed to run 1000 QPS = 1000 / 10= **100**

这给了我们一个提示，即单机处理作业的设计既不可能，也无法扩展。我们需要分布式系统来设计解决方案

## 系统接口

可向用户提供三个应用程序接口

- submitJob(api_key, user_id, job_schedule_time, job_type, priority, result_location)

这里，job_type = ONCE 或 RECURRING，result_location 可以是 AWS s3 的位置

接受任务后，API 可以返回 http 响应代码 202。

- viewJob(api_key, user_id, job_id)

响应包括 NOT_STARTED、STARTED 或 COMPLETED 状态


- listJobs（api_key、user_id、pagination_token）

用户可查询已提交的所有工作，并返回分页响应

## 高层次设计

![[Pasted image 20231110151239.png]]

### 用户请求流程

- (1 & 2) 用户通过连接负载均衡器（或 API 网关）提交/获取任务
- (3) 请求将在数据库中持久化，并向用户发送回执
- (4 & 5) 作业执行器服务将持续从数据库轮询到期作业，并将其保留在队列中
- (6 和 7) 作业执行器服务将执行实际作业业务逻辑，并将最终结果更新到文件系统，同时将状态更新为 "已完成"

### 数据库设计

由于我们对事务支持或任何其他 ACID 属性没有严格要求，同时考虑到峰值 QPS（2\*1000 = 2000 QPS），我们可以使用 SQL 或 NoSql 数据库。考虑到 NoSql 在规模、维护和成本方面的明显优势，我会选择使用 DynamoDb 的 NoSql 解决方案。

用户查询模式:

- 给出UserId，添加作业
- 给出UserId，查询所有作业


数据库Schema:

![[Pasted image 20231110151928.png]]


- job_status： 这是用户将看到的工作状态。可以是：NOT_STARTED（未启动）、STARTED（已启动）、COMPLETED（已完成）。
- execution_status： 执行状态： 这是我们的服务将保持的实际执行状态。它可以有 not_started, claimed, processing, success, retriable_failure, fatal_failure

除了用户，我们的作业调度服务还会轮询数据库，以获取到期的任务。我们可以通过不同的方式来实现这一点

1. 根据X分钟大小的桶窗口进行分区

我们可以创建名为 scheduledJob 的索引，以检索最近 X 分钟到期的工作

![[Pasted image 20231110152316.png]]

2. 根据 X 分钟大小的水桶窗口和分区 ID 进行分区

在某个时间窗口，可能会收到很多作业（例如 100K）。在这种情况下，上述查询性能将非常缓慢。我们可以根据随机（假设在 1 到 Y 之间）shard_id 进一步划分数据库。

![[Pasted image 20231110152605.png]]

## 更深入的设计细节

![[Pasted image 20231110152654.png]]

#### 这个作业调度器如何工作

作业调度流程

- 每隔 X 分钟，主节点会创建一个权威的 UNIX 时间戳，并为每个工作者分配一个分片 ID 和计划任务执行时间。
- Worker节点将执行以下查询，并将作业推送到 Kafka 队列中执行。

```sql
worker 1:
SELECT * FROM _ScheduledJob_ WHERE scheduled_job_execution_time == now() - X and shard_id = 1

worker 2:
SELECT * FROM _ScheduledJob_ WHERE scheduled_job_execution_time == now() - X and shard_id = 2
```

容错

- Master节点监控工作者的健康状况，知道哪个Worker死亡，以及如何将查询重新分配给新的Worker节点。
- 如果Master节点死亡，我们可以分配其他worker节点作为Master节点。
- 此外，我们还可以引入本地数据库来跟踪Worker是否已成功查询数据库，并将条目放入队列中。

#### 作业执行器如何工作

作业执行器服务有多个消费者，他们从队列中提取数据。消费者机器也有Master进程和Worker进程。Master进程和Worker进程都是基于 "pull "模式运行的。Master进程将从队列中轮询作业，而Worker进程将通过执行以下代码不断从Master进程轮询作业

```c
while True:  
	w := get_next_work()  
	do_work(w)
```

作业执行流程和容错

- 当作业从队列中被拾取时，消费者的Master进程会更新 JOB 数据库属性 execution_status=CLAIMED。
- 当Worker进程拾取作业时，它会更新 execution_status=PROCESSING，并持续向本地数据库发送健康检查。
- 作业完成后，Worker进程会将结果推送到 s3，更新 JOB 数据库的 execution_status=COMPLETED 或 FATAL_FAILED，并更新本地数据库的状态
- Worker进程和Master进程都将更新本地数据库中的健康检查。

健康检查服务

- 健康检查服务会定期运行（比如每 x 秒一次），并扫描数据库中上次从Worker进程收到的健康检查结果小于定义阈值的地方。在这种情况下，它会认为作业处理失败，并将条目推回队列。

## 参考

- Dropbox的一个异步任务调度框架 [How we designed Dropbox ATF: an async task framework - Dropbox](https://dropbox.tech/infrastructure/asynchronous-task-scheduling-at-dropbox) 
